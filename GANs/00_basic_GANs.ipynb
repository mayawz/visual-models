{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80fb2db1",
   "metadata": {},
   "source": [
    "# implimentation of a basic GAN\n",
    "- imports\n",
    "- load data\n",
    "- create the Generator and Discriminator classes\n",
    "- set up the hyperparameters, loss function, and optimizers\n",
    "- define loss functions for Discrinimator, Generator\n",
    "- define training loop \n",
    "- evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a141b03",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346b4a0",
   "metadata": {},
   "source": [
    "### load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = MNIST(root='.', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(mnist, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4782736",
   "metadata": {},
   "source": [
    "### create the Generator and Discriminator classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178500b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_samples, z_dim, device=device):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim),\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    '''\n",
    "    return torch.randn(n_samples,z_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27c23b-8a88-46fd-a0b2-d286def7f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator\n",
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        img_shape: [H,W] of the input image as input_image.shape\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, img_shape, z_dim=10, hidden_dim=128):\n",
    "\n",
    "        super(Generator, self).__init__()\n",
    "        self.im_dim = int(np.prod(img_shape))\n",
    "\n",
    "        def gen_block(in_feat, out_feat):\n",
    "            return nn.Sequential(\n",
    "                        nn.Linear(in_feat, out_feat),\n",
    "                        nn.BatchNorm1d(out_feat, 0.8),\n",
    "                        nn.ReLU(0.2, inplace=True)\n",
    "                    )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            gen_block(z_dim, hidden_dim),\n",
    "            gen_block(hidden_dim, hidden_dim * 2),\n",
    "            gen_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            gen_block(hidden_dim * 4, hidden_dim * 8),\n",
    "            nn.Linear(hidden_dim * 8, self.im_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        return self.model(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape, hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def dis_block(in_feat, out_feat):\n",
    "            return nn.Sequential(\n",
    "                        nn.Linear(in_feat, out_feat),\n",
    "                        nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            dis_block(int(np.prod(img_shape)), hidden_dim*4),\n",
    "            dis_block(hidden_dim*4, hidden_dim*2),\n",
    "            dis_block(hidden_dim*2, hidden_dim),\n",
    "            nn.Linear(hidden_dim,1)\n",
    "            # nn.Sigmoid() not needed for the loss function \n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.model(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d1905",
   "metadata": {},
   "source": [
    "### set up hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae5923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "img_shape = [28, 28]\n",
    "\n",
    "# Initialize generator, discriminator, and their optimizer\n",
    "gen = Generator(img_shape, z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "disc = Discriminator(img_shape).to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ac421",
   "metadata": {},
   "source": [
    "### define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
    "    '''\n",
    "    Return the loss of the discriminator given inputs.\n",
    "    Parameters:\n",
    "        gen: the generator model, which returns an image given z-dimensional noise\n",
    "        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n",
    "        criterion: the loss function, which should be used to compare \n",
    "               the discriminator's predictions to the ground truth reality of the images \n",
    "               (e.g. fake = 0, real = 1)\n",
    "        real: a batch of real images\n",
    "        num_images: the number of images the generator should produce, \n",
    "                which is also the length of the real images\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    Returns:\n",
    "        disc_loss: a torch scalar loss value for the current batch\n",
    "    '''\n",
    "\n",
    "    # generate a batch of num_images number of fake images\n",
    "    noise = get_noise(num_images, z_dim).to(device)\n",
    "    # generate the fake image via generator\n",
    "    fake_img = gen(noise).to(device)\n",
    "    # detach the fake image from generator and then make discriminator predictions\n",
    "    # (cal discriminator's loss, don't want gradient to flow back to generator)\n",
    "    pred_fake = disc(fake_img.detach()).to(device)\n",
    "    # calculate loss\n",
    "    # discriminator predict true=1 fake=0 and want's to be correct\n",
    "    loss_fake = criterion(pred_fake, torch.zeros_like(pred_fake)).to(device)\n",
    "    # same prediction and loss for label=1\n",
    "    pred_true = disc(real).to(device)\n",
    "    loss_true = criterion(pred_true, torch.ones_like(pred_true)).to(device)\n",
    "    # calculate average loss\n",
    "    disc_loss = torch.mean(torch.stack((loss_fake, loss_true))).to(device)\n",
    "    \n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea52d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    '''\n",
    "    Return the loss of the generator given inputs.\n",
    "    Parameters:\n",
    "        gen: the generator model, which returns an image given z-dimensional noise\n",
    "        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n",
    "        criterion: the loss function, which should be used to compare \n",
    "               the discriminator's predictions to the ground truth reality of the images \n",
    "               (e.g. fake = 0, real = 1)\n",
    "        num_images: the number of images the generator should produce, \n",
    "                which is also the length of the real images\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    Returns:\n",
    "        gen_loss: a torch scalar loss value for the current batch\n",
    "    '''\n",
    "    \n",
    "    # generate a batch of num_images number of fake images\n",
    "    noise = get_noise(num_images, z_dim).to(device)\n",
    "    # generate the fake image via generator\n",
    "    fake_img = gen(noise).to(device)\n",
    "    # !!! remember to remove .detach() from fake image before prediction so \n",
    "    # that the gradient will flow back to generator\n",
    "    pred_fake = disc(fake_img).to(device)\n",
    "    gen_loss = criterion(pred_fake, torch.ones_like(pred_fake)).to(device)\n",
    "    \n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18fc44",
   "metadata": {},
   "source": [
    "### training loop and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "\n",
    "test_generator = True \n",
    "display_step = 500\n",
    "\n",
    "gen_loss = False\n",
    "error = False\n",
    "\n",
    "def plot_tensor_of_imgs(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    plot a tensor of images, based on number of images, and size per image,\n",
    "    in a uniform grid.\n",
    "    '''\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for batch, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        current_batch_size = len(imgs)\n",
    "        \n",
    "        # Flatten the batch of real images from the data\n",
    "        real = real.view(current_batch_size, -1).to(device)\n",
    "\n",
    "        #  ######### Train Discriminator #########\n",
    "        # zero out the gradients before backprop\n",
    "        disc_opt.zero_grad()\n",
    "        # calc discriminator loss\n",
    "        disc_loss = get_disc_loss(gen, \n",
    "                                  disc, \n",
    "                                  criterion, \n",
    "                                  real, \n",
    "                                  current_batch_size, \n",
    "                                  z_dim, \n",
    "                                  device)\n",
    "        # update gradient \n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        # update optimizer\n",
    "        disc_opt.step()\n",
    "\n",
    "        #  ######### Train Generator #########\n",
    "        # to test the generator, to keep track of the generator weights\n",
    "        if test_generator:\n",
    "            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n",
    "        # zero out the gradients before backprop\n",
    "        gen_opt.zero_grad()\n",
    "        # calc generator loss\n",
    "        gen_loss = get_gen_loss(gen, \n",
    "                                disc, \n",
    "                                criterion, \n",
    "                                current_batch_size, \n",
    "                                z_dim, \n",
    "                                device)\n",
    "        # backprop update gradients\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        # update optimizer\n",
    "        gen_opt.step()\n",
    "\n",
    "        # to test the generator, to keep track of the generator weights\n",
    "        if test_generator:\n",
    "            try:\n",
    "                assert lr > 0.0000002 or (gen.gen[0][0].weight.grad.abs().max() < 0.0005 and epoch == 0)\n",
    "                assert torch.any(gen.gen[0][0].weight.detach().clone() != old_generator_weights)\n",
    "            except:\n",
    "                error = True\n",
    "                print(\"Runtime tests have failed\")\n",
    "        \n",
    "        # ######### print progress #########\n",
    "        if epoch % 100 == 0:\n",
    "            print(\n",
    "                f\"[Epoch {epoch}/{n_epochs}] [Batch {batch}/{len(dataloader)}] \"\n",
    "                f\"[D loss: {disc_loss.item():.4f}] [G loss: {gen_loss.item():.4f}]\"\n",
    "            )\n",
    "\n",
    "        # ######### visualize progress #########\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        # visualize training progress\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fake_noise = get_noise(current_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            plot_tensor_of_imgs(fake)\n",
    "            plot_tensor_of_imgs(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e66f18",
   "metadata": {},
   "source": [
    "### save for later eval/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e0959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# mkdir if not existing yet\n",
    "mdl_path = Path(\"models\")\n",
    "mdl_path.mkdir(parents=True, # create parent directories if needed\n",
    "               exist_ok=True # if models directory already exists, don't error\n",
    ")\n",
    "\n",
    "# Create model save path\n",
    "mdl_name_gen = \"basic_GAN_gen.pth\"\n",
    "mdl_name_disc = \"basic_GAN_disc.pth\"\n",
    "\n",
    "# Save the model state dict\n",
    "print(f\"Saving gen-disc models to: {mdl_path}\")\n",
    "torch.save(obj=gen.state_dict(), # only saving the state_dict() only saves the learned parameters\n",
    "           f=f\"{mdl_path} / {mdl_name_gen}\")\n",
    "torch.save(obj=disc.state_dict(), # only saving the state_dict() only saves the learned parameters\n",
    "           f=f\"{mdl_path} / {mdl_name_disc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
